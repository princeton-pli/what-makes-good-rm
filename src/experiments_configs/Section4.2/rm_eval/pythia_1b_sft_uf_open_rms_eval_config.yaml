do_sft: false
do_rlhf: false
do_rm_eval: true
do_rm: false

cache_dir: 
seed: 23

rm_eval_config:
  save_generated_responses: true
  only_lm_eval: false
  output_dir_base: outputs/open_rms_eval/pythia1b_uf
  dataset_path: FILL_PATH_TO_RELABELED_ULTRAFEEDBACK_DATASET_HERE
  load_dataset_from_file: true
  train_split: train_rlhf_prefs
  test_split: test_prefs
  num_train_samples: 500
  num_test_samples: 500
  data_selection_seed: 237
  rm_batch_size: 64
  lm_batch_size: 4
  language_model_path: FILL_PATH_TO_SFT_LANGUAGE_MODEL_PYTHIA1B_HERE
  ground_truth_reward_model_path: RLHFlow/ArmoRM-Llama3-8B-v0.1
  proxy_reward_models:
    - "Ray2333/GRM-Llama3.2-3B-rewardmodel-ft"
    - "allenai/llama-3-tulu-2-8b-uf-mean-rm"
    - "Ray2333/GRM-gemma2-2B-rewardmodel-ft"
    - "weqweasdas/RM-Gemma-2B"
  generation_config:
    temperature: 1
    #    max_length: 512
    max_new_tokens: 512
    do_sample: true
    num_return_sequences: 10

